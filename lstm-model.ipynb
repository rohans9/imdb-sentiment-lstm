{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cc3c8ae-398a-4dd4-ab44-a7311d46d525",
   "metadata": {},
   "source": [
    "# IMDb Movie Review Sentiment Prediction using LSTM\n",
    "\n",
    "**Name:** Rohan Sahu  \n",
    "**Registration Number:** 22BAI10166  \n",
    "**Date:** 05-04-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d430741-69c7-4e64-9c51-08ba50d99b31",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "When people watch a movie, they often head to platforms like **IMDb** to share what they thought about it. These reviews can be extremely valuable—not just for other viewers, but also for companies in the film industry trying to gauge public opinion. But with thousands of reviews being posted every day, going through them manually just isn’t feasible.\n",
    "\n",
    "This project focuses on building a model that can **predict the sentiment** of a movie review—whether it's **positive** or **negative**—based purely on the text. To do this, we’ll be using a deep learning model known as **LSTM (Long Short-Term Memory)**, which is good at handling sequences of data like sentences and paragraphs. Since LSTMs are capable of capturing context and relationships between words, they’re a solid choice for this task.\n",
    "\n",
    "The dataset we’re using is the **IMDb movie review dataset**, which contains **50,000 labeled reviews**—split evenly between positive and negative sentiments. The idea is to train the LSTM model on this data so that it can learn how sentiment is typically expressed in text and use that knowledge to make predictions on new reviews.\n",
    "\n",
    "### Challenges:\n",
    "- Dealing with informal language, sarcasm, or mixed emotions in reviews.\n",
    "- Making sure the model captures not just individual words, but how they're used in context.\n",
    "- Handling reviews of different lengths without losing important information.\n",
    "\n",
    "### Goal:\n",
    "Our goal is to develop a model that can reliably **predict the sentiment of reviews with high accuracy**—ideally **above 85% on the test data**. We'll also use evaluation metrics like:\n",
    "- **Accuracy**\n",
    "- **Precision**\n",
    "- **Recall**\n",
    "- **F1-score**\n",
    "\n",
    "…to measure performance, and **visualize results** to better understand how the model is learning over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265084a0-efd8-4d9c-8bbb-e76c76716afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71984b32-b5c9-4f38-8dc7-9b7114dc1145",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\Rohan Sahu\\\\Downloads\\\\IMDB\\\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ce4659-9c3d-491d-990c-f403f23617fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a213832-f1c1-4e62-bb5e-de146c659fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d7351e-0623-47b1-baeb-7dc4080d3bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Sahu\\AppData\\Local\\Temp\\ipykernel_5332\\2568826810.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data.replace({\"sentiment\": {\"positive\": 1, \"negative\": 0}}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.replace({\"sentiment\": {\"positive\": 1, \"negative\": 0}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa070616-886a-4128-9d55-2f0499accdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training data and test data\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e046a484-fb04-444e-8500-d6eb06dd3b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44e08e10-bc90-48ef-b08d-3d88e4e03e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data[\"review\"])\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"review\"]), maxlen=200)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"review\"]), maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5564b8b7-b5f4-4086-8ab4-7f1338eea4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    7   21 1128]\n",
      " [   0    0    0 ...    5   99  872]\n",
      " [   0    0    0 ... 1014   32 1742]\n",
      " ...\n",
      " [   0    0    0 ...    1    4 3144]\n",
      " [   0    0    0 ...  693  725  155]\n",
      " [ 363 1219   76 ...    1   95  141]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3125fca-40fd-4cd1-a841-4188461dd9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 460    4  249 ... 1094    6 4951]\n",
      " [ 137   61  140 ...  454  140   26]\n",
      " [   0    0    0 ...  273    3  163]\n",
      " ...\n",
      " [   0    0    0 ...  345    2 2466]\n",
      " [   0    0    0 ...   75   65   39]\n",
      " [   0    0    0 ...   21  246  342]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda64c12-ef58-4503-929a-2e91bcc375e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_data[\"sentiment\"]\n",
    "Y_test = test_data[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ac6625b-6e2d-45c4-92d3-86f9424fb6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380     0\n",
      "3385     1\n",
      "41779    0\n",
      "39302    0\n",
      "20619    1\n",
      "        ..\n",
      "42297    1\n",
      "33174    1\n",
      "46470    1\n",
      "34959    1\n",
      "10863    1\n",
      "Name: sentiment, Length: 40000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "988570e8-a408-4495-b8da-34b38cfdabdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohan Sahu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=200))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d493d63a-2163-45f2-a28c-ffe11d935929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18626aae-66fa-4e10-bbf1-d71bc578fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "170c0090-178b-403b-944b-81517b0a2d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 928ms/step - accuracy: 0.7353 - loss: 0.5193 - val_accuracy: 0.8349 - val_loss: 0.3919\n",
      "Epoch 2/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 2s/step - accuracy: 0.8559 - loss: 0.3512 - val_accuracy: 0.8485 - val_loss: 0.3508\n",
      "Epoch 3/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 926ms/step - accuracy: 0.8806 - loss: 0.2937 - val_accuracy: 0.8654 - val_loss: 0.3272\n",
      "Epoch 4/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 752ms/step - accuracy: 0.9014 - loss: 0.2488 - val_accuracy: 0.8704 - val_loss: 0.3257\n",
      "Epoch 5/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 772ms/step - accuracy: 0.9115 - loss: 0.2215 - val_accuracy: 0.8730 - val_loss: 0.3239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b94d4b70b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b4ef805-d74c-4016-8387-34d1baf7e441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - accuracy: 0.8782 - loss: 0.3113\n",
      "Test Loss: 0.32001858949661255\n",
      "Test Accuracy: 0.8755999803543091\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07717a29-4668-47a1-8fe8-58c67c7f1dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review):\n",
    "  # tokenize and pad the review\n",
    "  sequence = tokenizer.texts_to_sequences([review])\n",
    "  padded_sequence = pad_sequences(sequence, maxlen=200)\n",
    "  prediction = model.predict(padded_sequence)\n",
    "  sentiment = \"positive\" if prediction[0][0] > 0.5 else \"negative\"\n",
    "  return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e35c4333-44b7-43e1-abda-10c1a2b65adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "The sentiment of the review is: positive\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "new_review = \"An absolute masterpiece. The storytelling, cinematography, and acting were all top-notch. Easily one of the best films of the decade.\"\n",
    "sentiment = predict_sentiment(new_review)\n",
    "print(f\"The sentiment of the review is: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87ee849f-a22f-4ce6-a695-f06678f1e3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "The sentiment of the review is: negative\n"
     ]
    }
   ],
   "source": [
    "new_review = \"The acting felt wooden, and the dialogue was cringeworthy at best. I struggled to finish it.\"\n",
    "sentiment = predict_sentiment(new_review)\n",
    "print(f\"The sentiment of the review is: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9356a-872b-49ee-8746-1eb1f150a19e",
   "metadata": {},
   "source": [
    "### **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3d352b7-3d67-48c2-a5e1-679149d27688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 73ms/step\n",
      "Confusion Matrix:\n",
      " [[4349  590]\n",
      " [ 654 4407]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.88      0.87      4939\n",
      "    Positive       0.88      0.87      0.88      5061\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "Y_pred_probs = model.predict(X_test)\n",
    "Y_pred = (Y_pred_probs > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(classification_report(Y_test, Y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de580881-1895-4bf4-9d73-0dbfa252cd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
